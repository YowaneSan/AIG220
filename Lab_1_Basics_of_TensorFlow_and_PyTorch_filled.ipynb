{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fB0JxNT3vp9_"
   },
   "source": [
    "# Week 3 Lab - Basics of TensorFlow and PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oQau3LwWvp-A"
   },
   "source": [
    "## Verifying GPU Availability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yA1i3Cbmvp-B"
   },
   "source": [
    "### TensorFlow GPU Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aTGRGQARvp-B",
    "outputId": "60163045-ad27-45e7-bd3c-2bd5539d66a6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.15.0\n",
      "GPU is available for TensorFlow!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "if gpu_devices:\n",
    "    print(\"GPU is available for TensorFlow!\")\n",
    "else:\n",
    "    print(\"No GPU found for TensorFlow.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tifIVkJwvp-C"
   },
   "source": [
    "### PyTorch GPU Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CWB8mzpOvp-C",
    "outputId": "16ca23ca-212f-49fe-cba0-cc5965b13012",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.3.0\n",
      "GPU is available for PyTorch!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available for PyTorch!\")\n",
    "else:\n",
    "    print(\"No GPU found for PyTorch.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "adurDFykvp-C"
   },
   "source": [
    "## Creating and Training a Simple Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eRJqE4VEvp-D"
   },
   "source": [
    "### TensorFlow Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hv5BvomLvp-D",
    "outputId": "3c7719cb-c3b1-4a3c-b370-673537ece7cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 2s 0us/step\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 9s 4ms/step - loss: 0.2539 - accuracy: 0.9276 - val_loss: 0.1372 - val_accuracy: 0.9607\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1136 - accuracy: 0.9663 - val_loss: 0.0943 - val_accuracy: 0.9711\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0791 - accuracy: 0.9761 - val_loss: 0.0844 - val_accuracy: 0.9721\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0604 - accuracy: 0.9815 - val_loss: 0.0790 - val_accuracy: 0.9755\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0462 - accuracy: 0.9860 - val_loss: 0.0837 - val_accuracy: 0.9735\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0837 - accuracy: 0.9735\n",
      "Test accuracy: 0.9735\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load and preprocess the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(f'Test accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FsWA1NEIvp-D"
   },
   "source": [
    "### PyTorch Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U_3PoKjGvp-D",
    "outputId": "2b3ffdc7-d241-45be-a477-8f732cdf22e3",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.1931\n",
      "Epoch [2/5], Loss: 0.0363\n",
      "Epoch [3/5], Loss: 0.3085\n",
      "Epoch [4/5], Loss: 0.1344\n",
      "Epoch [5/5], Loss: 0.0438\n",
      "Test Accuracy: 96.21%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Load and preprocess the MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define the model\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(28*28, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleNN()\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Test Accuracy: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rpBk8gZHywti"
   },
   "source": [
    "---\n",
    "### Questions\n",
    "Answer the following questions in detail.\n",
    "\n",
    "1. What is the purpose of normalizing the input data in both TensorFlow and PyTorch implementations?\n",
    "2. Explain the role of the activation function relu in the neural network.\n",
    "3. Why is it important to use GPU for training neural networks?\n",
    "4. Compare the training time and accuracy of the TensorFlow and PyTorch models. Which one performed better and why?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Answer\n",
    "\n",
    "1. to prevent imbalance feature that would affect gradient during backpropagation in the training. as well as improve training time, by normalizing data\n",
    "some data that have very different range ie house price(range 500,000-1,000,000+) with area (500-1000) could take more time for the model to converge \n",
    "2. to introduce non-linearity to the model, without it the model will be single linear transformation (unable to pickup complex pattern)\n",
    "and being efficient - if the input is <0, the output is 0, if the input is >0, output remain the same\n",
    "3. Faster, GPU provide more processing power than CPU in both memory bandwidth and paralel processing that able to run multiple calculation at the same time (also seen usage in bitcoin mining, similar reason plus scalability that multiple GPU can be chain up together for evenmore computational power) on top of that is Manufacturer also provide optimized library for neural network/machine learning namely NVIDIA's cuDNN (CUDA Deep Neural Network library)\n",
    "4. Tensorflow (56 sec) is  faster than pytorch (1m 38 sec), but most of the setting is the same\n",
    "    - using same dataset (MNIST), same network structure (28*28 input, to 128 nodes in 2nd layer and 10 node in output layers)\n",
    "    - same optimizer as well being Adam and learning 0.001, (from quick check default learning rate is 0.001, so even it not set, both still using same value )\n",
    "    - same epoch count, same loss function (cross entropy)\n",
    "    so I think that it come down to be a example on tensorflow and pytorch performance, the library itself. that tensorflow is generally more efficient/powerful than pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
